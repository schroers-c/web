<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Christopher Schroers</title>
  <meta name="description" content="Personal Website">
  <meta name="author" content="Christopher Schroers">
  <meta name="google-site-verification" content="iqgXimqKqbbT0s0BOlR2lz_uv9hsB-JkKQDC7iAv0dQ" />
  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">
  <link href="style.css" rel="stylesheet">

  <template id="flex-template">
    <div style="display:flex;flex-direction:row; margin:0.1em;">
      <a href="#" class="link" target="_blank">
      <div style="display:flex;flex-direction:column;padding-left:0.5em; padding-top:0.0em; width:500px;
      min-height:100px;">
        <div class="title"></div>
        <div class="author"></div>
        <div class="conference"></div>
      </div>
      </a>
    </div>
  </template>

  <script type="text/javascript" src="bib.json"></script>
  <script>
    const books = [
       {
        title: 'Lossy Image Compression with Foundation Diffusion Models',
        author: 'L. Relic, R. Azevedo, M. Gross, C. Schroers',
        conference: '#',
        image: '#',
        url_paper: 'https://arxiv.org/pdf/2404.08580'
      },
       {
        title: 'Versatile Vision Foundation Model for Image and Video Colorization',
        author: 'V. Bozic, A. Djelouah Y. Zhang, R. Timofte, M. Gross, C. Schroers',
        conference: 'Siggraph 2024',
        image: '#',
        url_paper: 'https://studios.disneyresearch.com/2024/07/28/versatile-vision-foundation-model-for-image-and-video-colorization/'
      },
      {
        title: 'QUADify: Extracting Meshes with Pixel-level Details and Materials from Images',
        author: 'M. Frühauf, H. Riemenschneider, M. Gross, C. Schroers',
        conference: 'CVPR 2024',
        image: '#',
        url_paper: 'https://studios.disneyresearch.com/2024/06/05/quadify-extracting-meshes-with-pixel-level-details-and-materials-from-images/'
      },
      {
        title: 'DiVAS: Video and Audio Synchronization with Dynamic Frame Rates',
        author: 'C. Labrador, M. Akcay, E. Abecassis, J. Massich, C. Schroers',
        conference: 'CVPR 2024',
        image: '#',
        url_paper: 'https://studios.disneyresearch.com/2024/06/17/divas-video-and-audio-synchronization-with-dynamic-frame-rates/'
      },
      {
        title: 'Combining Frame and GOP Embeddings for Neural Video Representation',
        author: 'J. Saethre, R. Azevedo, C. Schroers',
        conference: 'CVPR 2024',
        image: '#',
        url_paper: 'https://studios.disneyresearch.com/2024/06/17/combining-frame-and-gop-embeddings-for-neural-video-representation/'
      },
      {
        title: 'Kernel-Based Frame Interpolation for Spatio-Temporally Adaptive Rendering',
        author: 'K Briedis, A. Djelouah, R. Ortiz, M. Meyer, M. Gross, C. Schroers',
        conference: 'Siggraph Asia 2023',
        image: '#',
        url_paper: 'https://studios.disneyresearch.com/app/uploads/2023/06/Kernel-Based-Frame-Interpolation-for-Spatio-Temporally.pdf'
      },
       {
        title: 'Video Compression With Entropy-Constrained Neural Representations',
        author: 'C. Gomes, R. Azevedo, C. Schroers',
        conference: 'CVPR 2023',
        image: '#',
        url_paper: 'https://openaccess.thecvf.com/content/CVPR2023/html/Gomes_Video_Compression_With_Entropy-Constrained_Neural_Representations_CVPR_2023_paper.html'
      },
      {
        title: 'Frame Interpolation Transformer and Uncertainty Guidance',
        author: 'M. Plack, K. Briedis, A. Djelouah, M. Hullin, M. Gross, C. Schroers',
        conference: 'CVPR 2023',
        image: '#',
        url_paper: 'https://openaccess.thecvf.com/content/CVPR2023/html/Plack_Frame_Interpolation_Transformer_and_Uncertainty_Guidance_CVPR_2023_paper.html'
      },
      {
        title: 'Kernel Aware Resampler',
        author: 'M. Bernasconi, A. Djelouah, F. Salehi, M. Gross, C. Schroers',
        conference: 'CVPR 2023',
        image: '#',
        url_paper: 'https://openaccess.thecvf.com/content/CVPR2023/html/Bernasconi_Kernel_Aware_Resampler_CVPR_2023_paper.html'
      },
       {
        title: 'Deep Adaptive Sampling and Reconstruction using Analytic Distributions',
        author: 'F. Salehi, M. Manzi, G. Röthlin, C. Schroers, R. Weber, M. Papas',
        conference: 'Siggraph Asia 2022',
        image: '#',
        url_paper: 'https://studios.disneyresearch.com/2022/11/30/deep-adaptive-sampling-and-reconstruction-using-analytic-distributions/'
      },
      {
        title: 'Neural Frame Interpolation for Rendered Content',
        author: 'K. Briedis, A. Djelouah, M. Meyer, I. McGonigal, M. Gross, C. Schroers',
        conference: 'Siggraph Asia 2021',
        image: '#',
        url_paper: 'https://studios.disneyresearch.com/2021/11/30/neural-frame-interpolation-for-rendered-content/'
      },
    {
        title: 'High Resolution Neural Face Swapping for Visual Effects',
        author: 'J. Naruniec, L. Helminger, C. Schroers, R. Weber',
        conference: 'EGSR 2020',
        image: 'pic1.jpg',
        url_paper: 'https://studios.disneyresearch.com/2020/06/29/high-resolution-neural-face-swapping-for-visual-effects/'
      },
      {
        title: 'Blind Image Super Resolution with Spatially Variant Degradations',
        author: 'V. Cornillère, A. Djelouah, Y. Wang, O. Sorkine-Hornung, C. Schroers',
        conference: 'SIGGRAPH Asia 2019',
        image: 'pic1.jpg',
        url_paper: 'https://studios.disneyresearch.com/2019/11/01/blind-image-super-resolution-with-spatially-variant-degradations/'
      }, {
        title: 'Deep Generative Video Compression',
        author: 'J. Han, S. Lombardo, C. Schroers, S. Mandt',
        conference: 'NeurIPS 2019',
        image: 'pic1.jpg',
        url_paper: 'https://studios.disneyresearch.com/2019/11/04/deep-generative-video-compression/'
      },
      {
        title: 'Neural Inter-Frame Compression for Video Coding',
        author: 'A. Djelouah, J. Campos, S. Schaub-Meyer, C. Schroers',
        conference: 'ICCV 2019',
        image: 'pic1.jpg',
        url_paper: 'https://studios.disneyresearch.com/2019/10/27/neural-inter-frame-compression-for-video-coding/'
      },
      {
        title: 'An Omnistereoscopic Video Pipeline for Capture and Display of Real-World VR',
        author: 'C. Schroers, J. Bazin, A. Sorkine-Hornung',
        conference: 'TOG 2018, presented at SIGGRAPH',
        image: 'pic1.jpg',
        url_paper: 'https://studios.disneyresearch.com/2018/08/09/an-omnistereoscopic-video-pipeline-for-capture-and-display-of-real-world-vr/'
      },
      {
        title: 'Normalized Cut Loss for Weakly-supervised CNN Segmentation',
        author: 'M. Tang, A. Djelouah, F. Perazzi, Y.Boykov, C.Schroers ',
        conference: 'CVPR 2018',
        image: 'pic1.jpg',
        url_paper: 'https://studios.disneyresearch.com/2018/06/18/normalized-cut-loss-for-weakly-supervised-cnn-segmentation/'
      },
      {
        title: 'On Regularized Losses for Weakly-supervised CNN Segmentation',
        author: 'M. Tang, F. Perazzi, A. Djelouah, I. Ben Ayed, C. Schroers, Y. Boykov',
        conference: 'ECCV 2018',
        image: 'pic1.jpg',
        url_paper: 'https://studios.disneyresearch.com/2018/09/08/on-regularized-losses-for-weakly-supervised-cnn-segmentation/'
      },
      {
        title: 'PhaseNet for Video Frame Interpolation',
        author: 'S. Meyer, A. Djelouah, B. McWilliams, A. Sorkine-Hornung, M. Gross, C. Schroers',
        conference: 'CVPR 2018',
        image: 'pic1.jpg',
        url_paper: 'http://openaccess.thecvf.com/content_cvpr_2018/papers/Meyer_PhaseNet_for_Video_CVPR_2018_paper.pdf'
      }
    ];
  </script>

</head>

<body>

  <div class="main-container">

    <div class="image-name-title" id="image-name-title">
      <img style="margin:0;width:200px;height:200px;
      border-radius: 50%; margin-top:1em; margin-right:1em;" src="Chris_Schroers.jpg" />

      <div class="name-title" style="display:flex; flex-direction:column;  align-items:left">
        <div style="font-size:50px;font-style:bold;color:#666666;">Christopher Schroers</div>
        <!--<div style="font-size:25px;color:#666666;">Research Scientist @ DisneyResearch|Studios</div>-->
        <div style="font-size:14px;color:#666666;width:550px;margin-top:1em">
          I am a Pricipal Research Scientist at DisneyResearch|Studios focusing on visual computing. More specifically, I am heading the Imaging
and Video Group which develops machine learning approaches for image and video processing tasks such as super resolution, frame
interpolation, and compression. In 2021, I have been honored with a Technology Emmy for work on video compression in collaboration
with DisneyStreaming for the Disney+ platform. Previously, my research targeted panoramic video processing for immersive VR
experiences and 3D reconstruction for set scanning. Please find a list of selected publications below.
        </div>
      </div>
    </div>

    <!--<div style="text-align:center;margin-top:100px;margin-bottom:15px">Selected Publications</div>-->
    <div style="display:flex; justify-content: center; padding:0px">
      <div id="publications" class="publications" />
    </div>
    <div>


      <script>
        'use strict';
        function appendBooks(templateId) {
          const booksList = document.getElementById('publications');
          const fragment = document.getElementById(templateId);

          booksList.innerHTML = '';

          books.forEach(book => {
            // Create an instance of the template content
            const instance = document.importNode(fragment.content, true);

            // Add relevant content to the template
            instance.querySelector('.title').innerHTML = book.title;
            instance.querySelector('.author').innerHTML = book.author;
            instance.querySelector('.conference').innerHTML = "(" + book.conference + ")";
            instance.querySelector('.link').href = book.url_paper;
            // instance.querySelector('.thumb').src = book.image;

            booksList.appendChild(instance);
          });
        }

        appendBooks('flex-template');
      </script>

</body>

</html>
